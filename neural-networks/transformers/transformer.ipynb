{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install the tensorflow"
      ],
      "metadata": {
        "id": "poKApMC8Ahm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEAXncpWTCbi",
        "outputId": "9a6affe1-f557-4eb5-d6ed-a3fea6e12140"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kE6iy7-eSovL"
      },
      "outputs": [],
      "source": [
        "from pickle import load, dump, HIGHEST_PROTOCOL\n",
        "from numpy.random import shuffle\n",
        "from numpy import savetxt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PrepareDataset:\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_sentences = 10000  # Number of sentences to include in the dataset\n",
        "        self.train_split = 0.8  # Ratio of the training data split\n",
        "        self.val_split = 0.1  # Ratio of the validation data split\n",
        "\n",
        "    # Fit a tokenizer\n",
        "    def create_tokenizer(self, dataset):\n",
        "        tokenizer = Tokenizer()\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return tokenizer\n",
        "\n",
        "    def find_seq_length(self, dataset):\n",
        "        return max(len(seq.split()) for seq in dataset)\n",
        "\n",
        "    def find_vocab_size(self, tokenizer, dataset):\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Encode and pad the input sequences\n",
        "    def encode_pad(self, dataset, tokenizer, seq_length):\n",
        "        x = tokenizer.texts_to_sequences(dataset)\n",
        "        x = pad_sequences(x, maxlen=seq_length, padding='post')\n",
        "        x = convert_to_tensor(x, dtype=int64)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_tokenizer(self, tokenizer, name):\n",
        "        with open(name + '_tokenizer.pkl', 'wb') as handle:\n",
        "            dump(tokenizer, handle, protocol=HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __call__(self, filename, **kwargs):\n",
        "        # Load a clean dataset\n",
        "        clean_dataset = load(open(filename, 'rb'))\n",
        "\n",
        "        # Reduce dataset size\n",
        "        dataset = clean_dataset[:self.n_sentences, :]\n",
        "\n",
        "        # Include start and end of string tokens\n",
        "        for i in range(dataset[:, 0].size):\n",
        "            dataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
        "            dataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
        "\n",
        "        # Random shuffle the dataset\n",
        "        shuffle(dataset)\n",
        "\n",
        "        # Split the dataset in training, validation and test sets\n",
        "        train = dataset[:int(self.n_sentences * self.train_split)]\n",
        "        val = dataset[int(self.n_sentences * self.train_split):\n",
        "                      int(self.n_sentences * (1-self.val_split))]\n",
        "        test = dataset[int(self.n_sentences * (1 - self.val_split)):]\n",
        "\n",
        "        # Prepare tokenizer for the encoder input\n",
        "        enc_tokenizer = self.create_tokenizer(dataset[:, 0])\n",
        "        enc_seq_length = self.find_seq_length(dataset[:, 0])\n",
        "        enc_vocab_size = self.find_vocab_size(enc_tokenizer, train[:, 0])\n",
        "\n",
        "        # Prepare tokenizer for the decoder input\n",
        "        dec_tokenizer = self.create_tokenizer(dataset[:, 1])\n",
        "        dec_seq_length = self.find_seq_length(dataset[:, 1])\n",
        "        dec_vocab_size = self.find_vocab_size(dec_tokenizer, train[:, 1])\n",
        "\n",
        "        # Encode and pad the training input\n",
        "        trainX = self.encode_pad(train[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        trainY = self.encode_pad(train[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Encode and pad the validation input\n",
        "        valX = self.encode_pad(val[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        valY = self.encode_pad(val[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Save the encoder tokenizer\n",
        "        self.save_tokenizer(enc_tokenizer, 'enc')\n",
        "\n",
        "        # Save the decoder tokenizer\n",
        "        self.save_tokenizer(dec_tokenizer, 'dec')\n",
        "\n",
        "        # Save the testing dataset into a text file\n",
        "        savetxt('test_dataset.txt', test, fmt='%s')\n",
        "\n",
        "        return (trainX, trainY, valX, valY, train, val, enc_seq_length,\n",
        "                dec_seq_length, enc_vocab_size, dec_vocab_size)\n"
      ],
      "metadata": {
        "id": "9uEIY-drSzA1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
        "from tensorflow.keras.layers import Dense, Layer\n",
        "from tensorflow.keras.backend import softmax\n",
        "\n",
        "# Implementing the Scaled-Dot Product Attention\n",
        "class DotProductAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, queries, keys, values, d_k, mask=None):\n",
        "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
        "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
        "\n",
        "        # Apply mask to the attention scores\n",
        "        if mask is not None:\n",
        "            scores += -1e9 * mask\n",
        "\n",
        "        # Computing the weights by a softmax operation\n",
        "        weights = softmax(scores)\n",
        "\n",
        "        # Computing the attention by a weighted sum of the value vectors\n",
        "        return matmul(weights, values)\n",
        "\n",
        "# Implementing the Multi-Head Attention\n",
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
        "        self.heads = h  # Number of attention heads to use\n",
        "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
        "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
        "        self.d_model = d_model  # Dimensionality of the model\n",
        "        self.W_q = Dense(d_k)   # Learned projection matrix for the queries\n",
        "        self.W_k = Dense(d_k)   # Learned projection matrix for the keys\n",
        "        self.W_v = Dense(d_v)   # Learned projection matrix for the values\n",
        "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
        "\n",
        "    def reshape_tensor(self, x, heads, flag):\n",
        "        if flag:\n",
        "            # Tensor shape after reshaping and transposing:\n",
        "            # (batch_size, heads, seq_length, -1)\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "        else:\n",
        "            # Reverting the reshaping and transposing operations:\n",
        "            # (batch_size, seq_length, d_k)\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
        "        return x\n",
        "\n",
        "    def call(self, queries, keys, values, mask=None):\n",
        "        # Rearrange the queries to be able to compute all heads in parallel\n",
        "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the keys to be able to compute all heads in parallel\n",
        "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the values to be able to compute all heads in parallel\n",
        "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Compute the multi-head attention output using the reshaped queries,\n",
        "        # keys, and values\n",
        "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange back the output into concatenated form\n",
        "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
        "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
        "\n",
        "        # Apply one final linear projection to the output to generate the multi-head\n",
        "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
        "        return self.W_o(output)\n"
      ],
      "metadata": {
        "id": "N5S0m6sXdIMW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Layer\n",
        "\n",
        "class PositionEmbeddingFixedWeights(Layer):\n",
        "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
        "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
        "        self.word_embedding_layer = Embedding(\n",
        "            input_dim=vocab_size, output_dim=output_dim,\n",
        "            weights=[word_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "        self.position_embedding_layer = Embedding(\n",
        "            input_dim=seq_length, output_dim=output_dim,\n",
        "            weights=[pos_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    def get_position_encoding(self, seq_len, d, n=10000):\n",
        "        P = np.zeros((seq_len, d))\n",
        "        for k in range(seq_len):\n",
        "            for i in np.arange(int(d/2)):\n",
        "                denominator = np.power(n, 2*i/d)\n",
        "                P[k, 2*i] = np.sin(k/denominator)\n",
        "                P[k, 2*i+1] = np.cos(k/denominator)\n",
        "        return P\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
        "        embedded_words = self.word_embedding_layer(inputs)\n",
        "        embedded_indices = self.position_embedding_layer(position_indices)\n",
        "        return embedded_words + embedded_indices\n"
      ],
      "metadata": {
        "id": "h2umytUmdH_m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
        "\n",
        "# Implementing the Add & Norm Layer\n",
        "class AddNormalization(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
        "\n",
        "    def call(self, x, sublayer_x):\n",
        "        # The sublayer input and output need to be of the same shape to be summed\n",
        "        add = x + sublayer_x\n",
        "\n",
        "        # Apply layer normalization to the sum\n",
        "        return self.layer_norm(add)\n",
        "\n",
        "# Implementing the Feed-Forward Layer\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, d_ff, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
        "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
        "        self.activation = ReLU()  # ReLU activation layer\n",
        "\n",
        "    def call(self, x):\n",
        "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
        "        x_fc1 = self.fully_connected1(x)\n",
        "\n",
        "        return self.fully_connected2(self.activation(x_fc1))\n",
        "\n",
        "# Implementing the Encoder Layer\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "\n",
        "    def call(self, x, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output = self.dropout1(multihead_output, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output = self.add_norm1(x, multihead_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm2(addnorm_output, feedforward_output)\n",
        "\n",
        "# Implementing the Encoder\n",
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
        "                       **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
        "                                                          d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
        "                              for _ in range(n)]\n",
        "\n",
        "    def call(self, input_sentence, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.encoder_layer):\n",
        "            x = layer(x, padding_mask, training)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "t_6Jb_PldHBe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, Dropout\n",
        "\n",
        "# Implementing the Decoder Layer\n",
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout3 = Dropout(rate)\n",
        "        self.add_norm3 = AddNormalization()\n",
        "\n",
        "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by another multi-head attention layer\n",
        "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,\n",
        "                                                      encoder_output, padding_mask)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output2)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm3(addnorm_output2, feedforward_output)\n",
        "\n",
        "# Implementing the Decoder\n",
        "class Decoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
        "                       **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
        "                                                          d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
        "                              for _ in range(n)]\n",
        "\n",
        "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(output_target)\n",
        "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.decoder_layer):\n",
        "            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "695qKS5sdGvA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import math, cast, float32, linalg, ones, maximum, newaxis\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class TransformerModel(Model):\n",
        "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length,\n",
        "                       h, d_k, d_v, d_model, d_ff_inner, n, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Set up the encoder\n",
        "        self.encoder = Encoder(enc_vocab_size, enc_seq_length, h, d_k, d_v,\n",
        "                               d_model, d_ff_inner, n, rate)\n",
        "\n",
        "        # Set up the decoder\n",
        "        self.decoder = Decoder(dec_vocab_size, dec_seq_length, h, d_k, d_v,\n",
        "                               d_model, d_ff_inner, n, rate)\n",
        "\n",
        "        # Define the final dense layer\n",
        "        self.model_last_layer = Dense(dec_vocab_size)\n",
        "\n",
        "    def padding_mask(self, input):\n",
        "        # Create mask which marks the zero padding values in the input by a 1.0\n",
        "        mask = math.equal(input, 0)\n",
        "        mask = cast(mask, float32)\n",
        "\n",
        "        # The shape of the mask should be broadcastable to the shape\n",
        "        # of the attention weights that it will be masking later on\n",
        "        return mask[:, newaxis, newaxis, :]\n",
        "\n",
        "    def lookahead_mask(self, shape):\n",
        "        # Mask out future entries by marking them with a 1.0\n",
        "        mask = 1 - linalg.band_part(ones((shape, shape)), -1, 0)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def call(self, encoder_input, decoder_input, training):\n",
        "\n",
        "        # Create padding mask to mask the encoder inputs and the encoder\n",
        "        # outputs in the decoder\n",
        "        enc_padding_mask = self.padding_mask(encoder_input)\n",
        "\n",
        "        # Create and combine padding and look-ahead masks to be fed into the decoder\n",
        "        dec_in_padding_mask = self.padding_mask(decoder_input)\n",
        "        dec_in_lookahead_mask = self.lookahead_mask(decoder_input.shape[1])\n",
        "        dec_in_lookahead_mask = maximum(dec_in_padding_mask, dec_in_lookahead_mask)\n",
        "\n",
        "        # Feed the input into the encoder\n",
        "        encoder_output = self.encoder(encoder_input, enc_padding_mask, training)\n",
        "\n",
        "        # Feed the encoder output into the decoder\n",
        "        decoder_output = self.decoder(decoder_input, encoder_output,\n",
        "                                      dec_in_lookahead_mask, enc_padding_mask, training)\n",
        "\n",
        "        # Pass the decoder output through a final dense layer\n",
        "        model_output = self.model_last_layer(decoder_output)\n",
        "\n",
        "        return model_output\n"
      ],
      "metadata": {
        "id": "cZMlw0dIf7eu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load, dump, HIGHEST_PROTOCOL\n",
        "from numpy.random import shuffle\n",
        "from numpy import savetxt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64\n",
        "\n",
        "class PrepareDataset:\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_sentences = 10000  # Number of sentences to include in the dataset\n",
        "        self.train_split = 0.8  # Ratio of the training data split\n",
        "        self.val_split = 0.1  # Ratio of the validation data split\n",
        "\n",
        "    # Fit a tokenizer\n",
        "    def create_tokenizer(self, dataset):\n",
        "        tokenizer = Tokenizer()\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return tokenizer\n",
        "\n",
        "    def find_seq_length(self, dataset):\n",
        "        return max(len(seq.split()) for seq in dataset)\n",
        "\n",
        "    def find_vocab_size(self, tokenizer, dataset):\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Encode and pad the input sequences\n",
        "    def encode_pad(self, dataset, tokenizer, seq_length):\n",
        "        x = tokenizer.texts_to_sequences(dataset)\n",
        "        x = pad_sequences(x, maxlen=seq_length, padding='post')\n",
        "        x = convert_to_tensor(x, dtype=int64)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_tokenizer(self, tokenizer, name):\n",
        "        with open(name + '_tokenizer.pkl', 'wb') as handle:\n",
        "            dump(tokenizer, handle, protocol=HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __call__(self, filename, **kwargs):\n",
        "        # Load a clean dataset\n",
        "        clean_dataset = load(open(filename, 'rb'))\n",
        "\n",
        "        # Reduce dataset size\n",
        "        dataset = clean_dataset[:self.n_sentences, :]\n",
        "\n",
        "        # Include start and end of string tokens\n",
        "        for i in range(dataset[:, 0].size):\n",
        "            dataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
        "            dataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
        "\n",
        "        # Random shuffle the dataset\n",
        "        shuffle(dataset)\n",
        "\n",
        "        # Split the dataset in training, validation and test sets\n",
        "        train = dataset[:int(self.n_sentences * self.train_split)]\n",
        "        val = dataset[int(self.n_sentences * self.train_split):\n",
        "                      int(self.n_sentences * (1-self.val_split))]\n",
        "        test = dataset[int(self.n_sentences * (1 - self.val_split)):]\n",
        "\n",
        "        # Prepare tokenizer for the encoder input\n",
        "        enc_tokenizer = self.create_tokenizer(dataset[:, 0])\n",
        "        enc_seq_length = self.find_seq_length(dataset[:, 0])\n",
        "        enc_vocab_size = self.find_vocab_size(enc_tokenizer, train[:, 0])\n",
        "\n",
        "        # Prepare tokenizer for the decoder input\n",
        "        dec_tokenizer = self.create_tokenizer(dataset[:, 1])\n",
        "        dec_seq_length = self.find_seq_length(dataset[:, 1])\n",
        "        dec_vocab_size = self.find_vocab_size(dec_tokenizer, train[:, 1])\n",
        "\n",
        "        # Encode and pad the training input\n",
        "        trainX = self.encode_pad(train[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        trainY = self.encode_pad(train[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Encode and pad the validation input\n",
        "        valX = self.encode_pad(val[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        valY = self.encode_pad(val[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Save the encoder tokenizer\n",
        "        self.save_tokenizer(enc_tokenizer, 'enc')\n",
        "\n",
        "        # Save the decoder tokenizer\n",
        "        self.save_tokenizer(dec_tokenizer, 'dec')\n",
        "\n",
        "        # Save the testing dataset into a text file\n",
        "        savetxt('test_dataset.txt', test, fmt='%s')\n",
        "\n",
        "        return (trainX, trainY, valX, valY, train, val, enc_seq_length,\n",
        "                dec_seq_length, enc_vocab_size, dec_vocab_size)\n"
      ],
      "metadata": {
        "id": "URA77DqAhGrX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow import data, train, math, reduce_sum, cast, equal, argmax, \\\n",
        "    float32, GradientTape, function\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from time import time\n",
        "from pickle import dump\n",
        "\n",
        "# Define the model parameters\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_model = 512  # Dimensionality of model layers' outputs\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "# Define the training parameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.98\n",
        "epsilon = 1e-9\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# Implementing a learning rate scheduler\n",
        "class LRScheduler(LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = cast(d_model, float32)\n",
        "        self.warmup_steps = cast(warmup_steps, float32)\n",
        "\n",
        "    def __call__(self, step_num):\n",
        "        # Linearly increasing the learning rate for the first warmup_steps, and\n",
        "        # decreasing it thereafter\n",
        "        step_num = cast(step_num, float32)\n",
        "        arg1 = step_num ** -0.5\n",
        "        arg2 = step_num * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return (self.d_model ** -0.5) * math.minimum(arg1, arg2)\n",
        "\n",
        "# Instantiate an Adam optimizer\n",
        "optimizer = Adam(LRScheduler(d_model), beta_1, beta_2, epsilon)\n",
        "\n",
        "# Prepare the training dataset\n",
        "dataset = PrepareDataset()\n",
        "trainX, trainY, valX, valY, train_orig, val_orig, enc_seq_length, \\\n",
        "    dec_seq_length, enc_vocab_size, dec_vocab_size = dataset('/content/sample_data/english-german-both.pkl')\n",
        "\n",
        "print(enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size)\n",
        "\n",
        "# Prepare the training dataset batches\n",
        "train_dataset = data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset batches\n",
        "val_dataset = data.Dataset.from_tensor_slices((valX, valY))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "# Create model\n",
        "training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
        "                                  dec_seq_length, h, d_k, d_v, d_model, d_ff, n,\n",
        "                                  dropout_rate)\n",
        "\n",
        "# Defining the loss function\n",
        "def loss_fcn(target, prediction):\n",
        "    # Create mask so that the zero padding values are not included in the\n",
        "    # computation of loss\n",
        "    mask = math.logical_not(equal(target, 0))\n",
        "    mask = cast(mask, float32)\n",
        "\n",
        "    # Compute a sparse categorical cross-entropy loss on the unmasked values\n",
        "    loss = sparse_categorical_crossentropy(target, prediction, from_logits=True) * mask\n",
        "\n",
        "    # Compute the mean loss over the unmasked values\n",
        "    return reduce_sum(loss) / reduce_sum(mask)\n",
        "\n",
        "\n",
        "# Defining the accuracy function\n",
        "def accuracy_fcn(target, prediction):\n",
        "    # Create mask so that the zero padding values are not included in the\n",
        "    # computation of accuracy\n",
        "    mask = math.logical_not(equal(target, 0))\n",
        "\n",
        "    # Find equal prediction and target values, and apply the padding mask\n",
        "    accuracy = equal(target, argmax(prediction, axis=2))\n",
        "    accuracy = math.logical_and(mask, accuracy)\n",
        "\n",
        "    # Cast the True/False values to 32-bit-precision floating-point numbers\n",
        "    mask = cast(mask, float32)\n",
        "    accuracy = cast(accuracy, float32)\n",
        "\n",
        "    # Compute the mean accuracy over the unmasked values\n",
        "    return reduce_sum(accuracy) / reduce_sum(mask)\n",
        "\n",
        "# Include metrics monitoring\n",
        "train_loss = Mean(name='train_loss')\n",
        "train_accuracy = Mean(name='train_accuracy')\n",
        "val_loss = Mean(name='val_loss')\n",
        "\n",
        "# Create a checkpoint object and manager to manage multiple checkpoints\n",
        "ckpt = train.Checkpoint(model=training_model, optimizer=optimizer)\n",
        "ckpt_manager = train.CheckpointManager(ckpt, \"./checkpoints\", max_to_keep=None)\n",
        "\n",
        "# Initialise dictionaries to store the training and validation losses\n",
        "train_loss_dict = {}\n",
        "val_loss_dict = {}\n",
        "\n",
        "# Speeding up the training process\n",
        "@function\n",
        "def train_step(encoder_input, decoder_input, decoder_output):\n",
        "    with GradientTape() as tape:\n",
        "\n",
        "        # Run the forward pass of the model to generate a prediction\n",
        "        prediction = training_model(encoder_input, decoder_input, training=True)\n",
        "\n",
        "        # Compute the training loss\n",
        "        loss = loss_fcn(decoder_output, prediction)\n",
        "\n",
        "        # Compute the training accuracy\n",
        "        accuracy = accuracy_fcn(decoder_output, prediction)\n",
        "\n",
        "    # Retrieve gradients of the trainable variables with respect to the training loss\n",
        "    gradients = tape.gradient(loss, training_model.trainable_weights)\n",
        "\n",
        "    # Update the values of the trainable variables by gradient descent\n",
        "    optimizer.apply_gradients(zip(gradients, training_model.trainable_weights))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy)\n",
        "\n",
        "start_time = time()\n",
        "for epoch in range(epochs):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    print(\"\\nStart of epoch %d\" % (epoch + 1))\n",
        "\n",
        "    # Iterate over the dataset batches\n",
        "    for step, (train_batchX, train_batchY) in enumerate(train_dataset):\n",
        "        # Define the encoder and decoder inputs, and the decoder output\n",
        "        encoder_input = train_batchX[:, 1:]\n",
        "        decoder_input = train_batchY[:, :-1]\n",
        "        decoder_output = train_batchY[:, 1:]\n",
        "\n",
        "        train_step(encoder_input, decoder_input, decoder_output)\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f\"Epoch {epoch + 1} Step {step} Loss {train_loss.result():.4f} \"\n",
        "                  + f\"Accuracy {train_accuracy.result():.4f}\")\n",
        "\n",
        "    # Run a validation step after every epoch of training\n",
        "    for val_batchX, val_batchY in val_dataset:\n",
        "        # Define the encoder and decoder inputs, and the decoder output\n",
        "        encoder_input = val_batchX[:, 1:]\n",
        "        decoder_input = val_batchY[:, :-1]\n",
        "        decoder_output = val_batchY[:, 1:]\n",
        "\n",
        "        # Generate a prediction\n",
        "        prediction = training_model(encoder_input, decoder_input, training=False)\n",
        "\n",
        "        # Compute the validation loss\n",
        "        loss = loss_fcn(decoder_output, prediction)\n",
        "        val_loss(loss)\n",
        "\n",
        "    # Print epoch number and accuracy and loss values at the end of every epoch\n",
        "    print(f\"Epoch {epoch+1}: Training Loss {train_loss.result():.4f}, \"\n",
        "          + f\"Training Accuracy {train_accuracy.result():.4f}, \"\n",
        "          + f\"Validation Loss {val_loss.result():.4f}\")\n",
        "\n",
        "    # Save a checkpoint after every epoch\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        save_path = ckpt_manager.save()\n",
        "        print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "        # Save the trained model weights\n",
        "        training_model.save_weights(\"weights/wghts\" + str(epoch + 1) + \".ckpt\")\n",
        "\n",
        "        train_loss_dict[epoch] = train_loss.result()\n",
        "        val_loss_dict[epoch] = val_loss.result()\n",
        "\n",
        "# Save the training loss values\n",
        "with open('./train_loss.pkl', 'wb') as file:\n",
        "    dump(train_loss_dict, file)\n",
        "\n",
        "# Save the validation loss values\n",
        "with open('./val_loss.pkl', 'wb') as file:\n",
        "    dump(val_loss_dict, file)\n",
        "\n",
        "print(\"Total time taken: %.2fs\" % (time() - start_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cschlg1PhlC4",
        "outputId": "38a3fc1a-5eb4-4444-8028-d21ac26a7651"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 12 2404 3864\n",
            "\n",
            "Start of epoch 1\n",
            "Epoch 1 Step 0 Loss 8.3741 Accuracy 0.0000\n",
            "Epoch 1 Step 50 Loss 7.6713 Accuracy 0.1447\n",
            "Epoch 1 Step 100 Loss 7.0778 Accuracy 0.1821\n",
            "Epoch 1: Training Loss 6.8673, Training Accuracy 0.1955, Validation Loss 5.7060\n",
            "Saved checkpoint at epoch 1\n",
            "\n",
            "Start of epoch 2\n",
            "Epoch 2 Step 0 Loss 5.7586 Accuracy 0.2837\n",
            "Epoch 2 Step 50 Loss 5.5952 Accuracy 0.2733\n",
            "Epoch 2 Step 100 Loss 5.3899 Accuracy 0.2812\n",
            "Epoch 2: Training Loss 5.3116, Training Accuracy 0.2842, Validation Loss 4.9251\n",
            "Saved checkpoint at epoch 2\n",
            "\n",
            "Start of epoch 3\n",
            "Epoch 3 Step 0 Loss 4.8790 Accuracy 0.3114\n",
            "Epoch 3 Step 50 Loss 4.7982 Accuracy 0.3076\n",
            "Epoch 3 Step 100 Loss 4.6542 Accuracy 0.3246\n",
            "Epoch 3: Training Loss 4.6087, Training Accuracy 0.3295, Validation Loss 4.3636\n",
            "Saved checkpoint at epoch 3\n",
            "\n",
            "Start of epoch 4\n",
            "Epoch 4 Step 0 Loss 4.3035 Accuracy 0.3529\n",
            "Epoch 4 Step 50 Loss 4.2846 Accuracy 0.3700\n",
            "Epoch 4 Step 100 Loss 4.1787 Accuracy 0.3825\n",
            "Epoch 4: Training Loss 4.1424, Training Accuracy 0.3864, Validation Loss 4.0403\n",
            "Saved checkpoint at epoch 4\n",
            "\n",
            "Start of epoch 5\n",
            "Epoch 5 Step 0 Loss 3.8890 Accuracy 0.4083\n",
            "Epoch 5 Step 50 Loss 3.9086 Accuracy 0.4107\n",
            "Epoch 5 Step 100 Loss 3.8264 Accuracy 0.4183\n",
            "Epoch 5: Training Loss 3.7951, Training Accuracy 0.4223, Validation Loss 3.7943\n",
            "Saved checkpoint at epoch 5\n",
            "\n",
            "Start of epoch 6\n",
            "Epoch 6 Step 0 Loss 3.5774 Accuracy 0.4394\n",
            "Epoch 6 Step 50 Loss 3.5997 Accuracy 0.4422\n",
            "Epoch 6 Step 100 Loss 3.5203 Accuracy 0.4508\n",
            "Epoch 6: Training Loss 3.4912, Training Accuracy 0.4543, Validation Loss 3.5666\n",
            "Saved checkpoint at epoch 6\n",
            "\n",
            "Start of epoch 7\n",
            "Epoch 7 Step 0 Loss 3.3081 Accuracy 0.5017\n",
            "Epoch 7 Step 50 Loss 3.3162 Accuracy 0.4725\n",
            "Epoch 7 Step 100 Loss 3.2487 Accuracy 0.4807\n",
            "Epoch 7: Training Loss 3.2230, Training Accuracy 0.4832, Validation Loss 3.3624\n",
            "Saved checkpoint at epoch 7\n",
            "\n",
            "Start of epoch 8\n",
            "Epoch 8 Step 0 Loss 3.0063 Accuracy 0.5087\n",
            "Epoch 8 Step 50 Loss 3.0668 Accuracy 0.4986\n",
            "Epoch 8 Step 100 Loss 3.0104 Accuracy 0.5033\n",
            "Epoch 8: Training Loss 2.9890, Training Accuracy 0.5051, Validation Loss 3.2415\n",
            "Saved checkpoint at epoch 8\n",
            "\n",
            "Start of epoch 9\n",
            "Epoch 9 Step 0 Loss 2.8303 Accuracy 0.5329\n",
            "Epoch 9 Step 50 Loss 2.8670 Accuracy 0.5147\n",
            "Epoch 9 Step 100 Loss 2.8105 Accuracy 0.5202\n",
            "Epoch 9: Training Loss 2.7894, Training Accuracy 0.5224, Validation Loss 3.1602\n",
            "Saved checkpoint at epoch 9\n",
            "\n",
            "Start of epoch 10\n",
            "Epoch 10 Step 0 Loss 2.6481 Accuracy 0.5329\n",
            "Epoch 10 Step 50 Loss 2.6638 Accuracy 0.5344\n",
            "Epoch 10 Step 100 Loss 2.6059 Accuracy 0.5394\n",
            "Epoch 10: Training Loss 2.5843, Training Accuracy 0.5414, Validation Loss 3.0676\n",
            "Saved checkpoint at epoch 10\n",
            "\n",
            "Start of epoch 11\n",
            "Epoch 11 Step 0 Loss 2.4384 Accuracy 0.5536\n",
            "Epoch 11 Step 50 Loss 2.4605 Accuracy 0.5568\n",
            "Epoch 11 Step 100 Loss 2.4029 Accuracy 0.5609\n",
            "Epoch 11: Training Loss 2.3837, Training Accuracy 0.5630, Validation Loss 2.9312\n",
            "Saved checkpoint at epoch 11\n",
            "\n",
            "Start of epoch 12\n",
            "Epoch 12 Step 0 Loss 2.2397 Accuracy 0.5675\n",
            "Epoch 12 Step 50 Loss 2.2764 Accuracy 0.5720\n",
            "Epoch 12 Step 100 Loss 2.2174 Accuracy 0.5788\n",
            "Epoch 12: Training Loss 2.2012, Training Accuracy 0.5803, Validation Loss 2.8640\n",
            "Saved checkpoint at epoch 12\n",
            "\n",
            "Start of epoch 13\n",
            "Epoch 13 Step 0 Loss 2.0606 Accuracy 0.6055\n",
            "Epoch 13 Step 50 Loss 2.0729 Accuracy 0.5978\n",
            "Epoch 13 Step 100 Loss 2.0280 Accuracy 0.6016\n",
            "Epoch 13: Training Loss 2.0109, Training Accuracy 0.6038, Validation Loss 2.8710\n",
            "Saved checkpoint at epoch 13\n",
            "\n",
            "Start of epoch 14\n",
            "Epoch 14 Step 0 Loss 1.8934 Accuracy 0.6263\n",
            "Epoch 14 Step 50 Loss 1.9096 Accuracy 0.6182\n",
            "Epoch 14 Step 100 Loss 1.8617 Accuracy 0.6224\n",
            "Epoch 14: Training Loss 1.8474, Training Accuracy 0.6235, Validation Loss 2.7911\n",
            "Saved checkpoint at epoch 14\n",
            "\n",
            "Start of epoch 15\n",
            "Epoch 15 Step 0 Loss 1.7167 Accuracy 0.6194\n",
            "Epoch 15 Step 50 Loss 1.7334 Accuracy 0.6392\n",
            "Epoch 15 Step 100 Loss 1.6942 Accuracy 0.6428\n",
            "Epoch 15: Training Loss 1.6827, Training Accuracy 0.6449, Validation Loss 2.6518\n",
            "Saved checkpoint at epoch 15\n",
            "\n",
            "Start of epoch 16\n",
            "Epoch 16 Step 0 Loss 1.5747 Accuracy 0.6540\n",
            "Epoch 16 Step 50 Loss 1.5774 Accuracy 0.6608\n",
            "Epoch 16 Step 100 Loss 1.5379 Accuracy 0.6650\n",
            "Epoch 16: Training Loss 1.5302, Training Accuracy 0.6655, Validation Loss 2.6549\n",
            "Saved checkpoint at epoch 16\n",
            "\n",
            "Start of epoch 17\n",
            "Epoch 17 Step 0 Loss 1.4614 Accuracy 0.7024\n",
            "Epoch 17 Step 50 Loss 1.4369 Accuracy 0.6800\n",
            "Epoch 17 Step 100 Loss 1.3880 Accuracy 0.6867\n",
            "Epoch 17: Training Loss 1.3751, Training Accuracy 0.6894, Validation Loss 2.6048\n",
            "Saved checkpoint at epoch 17\n",
            "\n",
            "Start of epoch 18\n",
            "Epoch 18 Step 0 Loss 1.2977 Accuracy 0.7232\n",
            "Epoch 18 Step 50 Loss 1.2692 Accuracy 0.7089\n",
            "Epoch 18 Step 100 Loss 1.2283 Accuracy 0.7144\n",
            "Epoch 18: Training Loss 1.2210, Training Accuracy 0.7157, Validation Loss 2.5818\n",
            "Saved checkpoint at epoch 18\n",
            "\n",
            "Start of epoch 19\n",
            "Epoch 19 Step 0 Loss 1.1622 Accuracy 0.7370\n",
            "Epoch 19 Step 50 Loss 1.1620 Accuracy 0.7250\n",
            "Epoch 19 Step 100 Loss 1.1232 Accuracy 0.7296\n",
            "Epoch 19: Training Loss 1.1093, Training Accuracy 0.7320, Validation Loss 2.5931\n",
            "Saved checkpoint at epoch 19\n",
            "\n",
            "Start of epoch 20\n",
            "Epoch 20 Step 0 Loss 1.0770 Accuracy 0.7439\n",
            "Epoch 20 Step 50 Loss 1.0405 Accuracy 0.7438\n",
            "Epoch 20 Step 100 Loss 1.0150 Accuracy 0.7469\n",
            "Epoch 20: Training Loss 1.0017, Training Accuracy 0.7495, Validation Loss 2.6182\n",
            "Saved checkpoint at epoch 20\n",
            "Total time taken: 7347.48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from matplotlib.pylab import plt\n",
        "from numpy import arange\n",
        "\n",
        "# Load the training and validation loss dictionaries\n",
        "train_loss = load(open('train_loss.pkl', 'rb'))\n",
        "val_loss = load(open('val_loss.pkl', 'rb'))\n",
        "\n",
        "# Retrieve each dictionary's values\n",
        "train_values = train_loss.values()\n",
        "val_values = val_loss.values()\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1, 21)\n",
        "\n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(epochs, train_values, label='Training Loss')\n",
        "plt.plot(epochs, val_values, label='Validation Loss')\n",
        "\n",
        "# Add in a title and axes labels\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Set the tick locations\n",
        "plt.xticks(arange(0, 21, 2))\n",
        "\n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vluurgUZhGmf",
        "outputId": "42966306-768f-40c4-96e9-ba4dbf574794"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lk4X1vk8f7VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5t9bKlSGgntn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8OrcFeHgnre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "273tjmINgno_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAm0k2O4gnmn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}